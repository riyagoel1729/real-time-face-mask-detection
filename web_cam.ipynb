{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0 (SDL 2.0.12, python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "    \n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "    faces = []\n",
    "    locs = []\n",
    "    preds = []\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        \n",
    "        if confidence > 0.3:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            \n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "            \n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "            face = np.expand_dims(face, axis=0)\n",
    "            faces.append(face)\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "            \n",
    "            if len(faces) > 0:\n",
    "                preds = maskNet.predict(faces)\n",
    "    return (locs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face detector model...\n",
      "[INFO] loading face mask detector model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading face detector model...\")\n",
    "\n",
    "faceNet = cv2.dnn.readNetFromCaffe(\"deploy.prototxt\",\"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "maskNet = load_model(\"mask_detector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound= mixer.Sound(\"alarm.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n",
      "Image 0saved\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=800,height=800)\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "    count=0\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        if mask > withoutMask:\n",
    "            label = \"Mask\"\n",
    "            cv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            label = \"{}: {:.2f}%\".format(label,mask* 100)\n",
    "            \n",
    "        elif mask < withoutMask:\n",
    "            label = \"No Mask\"\n",
    "            cv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),  (0, 0, 255), 2)\n",
    "            label = \"{}: {:.2f}%\".format(label,withoutMask* 100)\n",
    "            sound.play()\n",
    "            \n",
    "            \n",
    "        \n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if mask < withoutMask:\n",
    "             img=vs.read()\n",
    "             print(\"Image \"+str(count)+\"saved\")\n",
    "             file='C:/Users/Vaishali/Desktop/Image/frame'+str(count)+'.jpg'\n",
    "             cv2.imwrite(file, frame)\n",
    "             \n",
    "        if key == ord(\"q\"):\n",
    "             break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
